# Code Vector CLI Configuration
# Copy this file to ~/.code-vector-db.env and configure as needed

# =============================================================================
# Embedding Provider
# =============================================================================

# Use OpenAI embeddings instead of local models (faster, requires API key)
# Options: true, false
# Default: false (uses local CodeT5+ and mpnet models)
USE_OPENAI_EMBEDDINGS=false

# OpenAI API Configuration (only if USE_OPENAI_EMBEDDINGS=true)
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# =============================================================================
# Qdrant Vector Database
# =============================================================================

# Qdrant server connection
# Default: localhost:6333
QDRANT_HOST=localhost
QDRANT_PORT=6333

# =============================================================================
# Performance Tuning
# =============================================================================

# Number of CPU cores to use for parsing (default: 50% of available cores)
# Uncomment to override:
# PARSE_WORKERS=8

# Batch size for file processing (default: 800)
# Uncomment to override:
# BATCH_SIZE=800

# =============================================================================
# Model Cache Location
# =============================================================================

# Directory for cached embedding models (default: ~/.local/share/code-vector-db/models)
# Uncomment to override:
# TRANSFORMERS_CACHE=/custom/path/to/models
# SENTENCE_TRANSFORMERS_HOME=/custom/path/to/models
